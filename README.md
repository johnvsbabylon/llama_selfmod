# llama_selfmod
A self-modifying inference engine built on llama-cpp-2. This Rust-based tool allows an LLM to perform real-time self-correction. Based on token confidence, it can adapt its own sampling parameters on the fly or retract and regenerate text to improve the quality and coherence of its output. I am not claiming perfection.
